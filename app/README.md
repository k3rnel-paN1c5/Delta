# Deep Vision - Depth Estimation App 

This is a Flutter-based mobile application that demonstrates real-time depth estimation from a single image using a lightweight machine learning model. The application allows users to pick an image from their gallery and see the corresponding depth map generated by the model.

## ðŸŒŸ Features

* **Image Selection**: Pick images from the device's gallery.
* **Depth Estimation**: Utilizes a TensorFlow Lite model to predict the depth of objects in the selected image.
* **Real-time Processing**: Designed to be lightweight and performant for mobile devices.
* **Cross-Platform**: Built with Flutter for a consistent experience on both Android and iOS.
* **User-Friendly Interface**: Simple and intuitive UI to display the original image and the resulting depth map.

---

## ðŸš€ Getting Started

Follow these instructions to get a copy of the project up and running on your local machine for development and testing purposes.

### Prerequisites

* Flutter SDK: [Installation Guide](https://docs.flutter.dev/get-started/install)
* An IDE like Android Studio or VS Code with the Flutter plugin.
* An Android or iOS device/emulator.

### Installation

1.  **Clone the repository:**
    ```bash
    git clone [https://github.com/k3rnel-paN1c5/deep-vision.git](https://github.com/k3rnel-paN1c5/deep-vision.git)
    cd app
    ```
2.  **Install dependencies:**
    ```bash
    flutter pub get
    ```
<!-- 3.  **Place the TFLite model:**
    * Obtain the `depth_model.tflite` file.
    * Create an `assets` directory in the root of the project.
    * Place the `depth_model.tflite` file inside the `assets` directory.
    * Uncomment the assets section in the `pubspec.yaml` file:
        ```yaml
        assets:
          - assets/depth_model.tflite
        ``` -->

3.  **Run the app:**
    ```bash
    flutter run
    ```

---

## ðŸ“± How to Use

1.  Launch the application on your device.
2.  Tap the "**Pick Image from Gallery**" button to select an image.
3.  The app will automatically process the image and display the original image and the generated depth map.

---

## ðŸ“‚ Project Structure

The project follows the standard Flutter project structure. Here are some of the key files and directories:

```
app/
â”œâ”€â”€ android/          # Android specific files
â”œâ”€â”€ ios/              # iOS specific files
â”œâ”€â”€ lib/
â”‚   â””â”€â”€ main.dart     # Main application code
â”œâ”€â”€ assets/
â”‚   â””â”€â”€ depth_model.tflite # (To be added) TFLite model file
â”œâ”€â”€ pubspec.yaml      # Project dependencies and configuration
â””â”€â”€ README.md         # This file
```

--- 

## ðŸ’» Technologies Used

* **Flutter**: For building the cross-platform mobile application.
* **Dart**: The programming language used for Flutter development.
* **TensorFlow Lite**: The machine learning framework for running the model on-device. The `tflite_flutter` package is used for this.
* **image_picker**: A Flutter plugin for selecting images from the device gallery.
* **image**: A Dart library for image processing.

---

## ðŸ”® Future Work

* Integrate a pre-trained depth estimation model.
* Implement a live camera feed for real-time depth estimation.
* Improve the accuracy and performance of the model.
* Add more post-processing options for the depth map.